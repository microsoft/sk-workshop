{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB03a - AI Plugins and Orchestration in Semantic Kernel\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - AI plugins in Semantic Kernel\n",
    "\n",
    "In this lab, we will learn how to use Semantic Kernel to build native and semantic functions and group them together as AI Plugins. We'll work on the following steps:\n",
    "\n",
    "1) What are AI Plugins? \n",
    "2) Create and add Semantic Functions to a Plugin.\n",
    "3) Use Semantic Kernel Tools to add a new Semantic Function\n",
    "4) Create and add a Native Function to a Plugin.\n",
    "5) Puting it all together for a Call Center Analytics solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, please ensure you have a `.env` file in your lesson directory. For this lesson, we'll also require two additional entries for Azure AI Speech and Azure AI Speech Region. Update the cell below and run it to create your `.env` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .env\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"\" #Model Deployment name, like gpt-35-turbo-instruct\n",
    "AZURE_OPENAI_ENDPOINT=\"\" #Azure OpenAI Service endpoint, like https://cog-azopenai-demos.openai.azure.com/\n",
    "AZURE_OPENAI_API_KEY=\"\" #Azure OpenAI Service API Key\n",
    "AZURE_AI_SPEECH_KEY=\"\" #Azure Speech Service API Key\n",
    "AZURE_AI_SPEECH_REGION=\"\" #Azure Speech Service Region, like brazilsouth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - What are AI Plugins?\n",
    "As the Copilot concept evolves, it's important to think on ways to extend their capabilities, allowing them to retrieve external information, interact with external services and execute actions on the behavior of the user on a safer way, following Responsible AI principles.\n",
    "\n",
    "The concept of **Plugins** is an answer to this, as they can act as a \"bridge\" between Copilots / AI Apps and the digital world. \n",
    "![Plugins Overview](images/plugins_overview.png)\n",
    "\n",
    "With Plugins, it's possible to expand Copilots capabilities and promote interoperability across the industry as Semantic Kernel adopts an open standard for plugins, the [OpenAPI Specification](https://swagger.io/specification/).\n",
    "\n",
    "Let's get started with the creation of Functions, which will be the base of our AI Plugins. In Semantic Kernel we can think of Plugins as a collection of functions. Let's see in the following sections how we can create functions and group them together as a Plugin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Create and add a Semantic Function to a Plugin\n",
    "\n",
    "In the first lesson, we have created and used an [**inline**](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/plugins/semantic-functions/inline-semantic-functions?tabs=python) Semantic Function to categorize a call.However this approach is fine for development and testing, we need a more robust way to ensure we can reuse the functions across projects and rapidly maintain / change the prompts and function parameters as required.\n",
    "\n",
    "Therefore, we'll now explore how we can reuse such functions. Semantic Kernel allows us to import files to define functions. We must follow a standard folder structure when creating the files. Here's an example:\n",
    "\n",
    "```\n",
    "📁 plugins\n",
    "│\n",
    "└─── 📂 plugin_name_A\n",
    "     |\n",
    "     └─── 📂 function_name_A \n",
    "     |      |\n",
    "     |      └───📄 skprompt.txt\n",
    "     |      └───📄 config.json\n",
    "     |\n",
    "     └─── 📂 function_name_B \n",
    "            |\n",
    "            └───📄 skprompt.txt\n",
    "            └───📄 config.json\n",
    "    📂 plugin_name_B\n",
    "     |\n",
    "     └─── 📂 function_name_C \n",
    "            |\n",
    "            └───📄 skprompt.txt\n",
    "            └───📄 config.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a variable to represent our Plugins folder. It'll be refered later to Import the plugins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define where the plugins are stored. If your plugins are in a different directory, change this parameter.\n",
    "plugins_directory = \"./plugins\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this structure in mind, we already start organizing our plugins and grouping together functions that belong to a plugin. For each Function (represented by a Folder) we must have two files:\n",
    "* **skprompt.txt**: it's the file that will contain the prompt of a Semantic Function. Therefore, we can easily maintain our functions by reviewing the prompts;\n",
    "* **config.json**: it's a configuration file that will describe the function in natural language, define which parameters the function requires, and the overall configuration the LLM should use run that function, such as temperature and maximum number of tokens. \n",
    "\n",
    "With this structure in mind, we already undestand how to create a folder structure to contain the funcions for a Call Center solution plugin. In this lesson, we'll recreate the function used before to fit into this structure.\n",
    "\n",
    "To get started, run the cell below to create a new file called `skprompt.txt` file inside the Semantic Function \"categorize\" under \"CallCenter\" plugin. This file represents the Prompt our function will perform and all input parameters that we want to change in runtime, such as the problem description _{{$problem}}_ and the list with the categories the company use _{{$categories}}_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile plugins/CallCenterPlugin/categorize/skprompt.txt\n",
    "You help a telco company to classify problems reported by their subscribers. Your role is to provide accurate classification based on problems description and a list of categories that the telco company uses.\n",
    "Classify the problem in one of the provided categories. Only write the output category with no extra text.\n",
    "Only write one category per problem description.\n",
    "\n",
    "Examples: \n",
    "Problem: My 5G is not working well when I'm in my car.\n",
    "Categories: Fixed Internet/Wifi, Mobile Internet.\n",
    "Output Category: Mobile Internet\n",
    "\n",
    "Problem: My TV is not streaming well from Youtube. It seems that the wifi in my bedroom is weak.\n",
    "Categories: Mobile Internet, TV, Fixed Internet/Wifi.\n",
    "Output Category: Fixed Internet/Wifi\n",
    "\n",
    "Problem: It's impossible to work today, my internet here in my home is so slow!\n",
    "Categories: Landiline, Mobile Internet, TV, Fixed Internet/Wifi.\n",
    "Output Category: Fixed Internet/Wifi\n",
    "\n",
    "Problem: {{$input}}\n",
    "Categories: {{$categories}}\n",
    "Output Category: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll review the `config.json` file to ensure it correctly describes our function. This file will define how the model should execute our prompt. Notice the parameters such as the number of tokens, temperature and description of the function and input parameters.\n",
    "\n",
    "Run the cell below to create the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile plugins/CallCenterPlugin/categorize/config.json\n",
    "{\n",
    "    \"schema\": 1,\n",
    "    \"type\": \"completion\",\n",
    "    \"description\": \"Classify a problem report in a call to the telco company based on provided categories.\",\n",
    "    \"completion\": {\n",
    "         \"max_tokens\": 10,\n",
    "         \"temperature\": 0.5,\n",
    "         \"top_p\": 0.0,\n",
    "         \"presence_penalty\": 0.0,\n",
    "         \"frequency_penalty\": 0.0\n",
    "    },\n",
    "    \"input\": {\n",
    "         \"parameters\": [\n",
    "              {\n",
    "                   \"name\": \"input\",\n",
    "                   \"description\": \"The problem reported by the user that needs to be classified. Required parameter.\",\n",
    "                   \"defaultValue\": \"\"\n",
    "              },\n",
    "              {\n",
    "                   \"name\": \"categories\",\n",
    "                   \"description\": \"A set of categories used by the telco company to classify the problems. Required parameter.\",\n",
    "                   \"defaultValue\": \"\"\n",
    "              }\n",
    "         ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this moment, your Plugins folder should have _at least_ the structure below.\n",
    "```\n",
    "📁 plugins\n",
    "│\n",
    "└─── 📂 CallCenterPlugin\n",
    "     |\n",
    "     └─── 📂 categorize \n",
    "     |      |\n",
    "     |      └───📄 skprompt.txt\n",
    "     |      └───📄 config.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To manipulate functions, we need to ensure we have all our pre-requirements set, as we did in the previous lesson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "\n",
    "#Importing the Azure Text Completion service connector\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion#AzureTextCompletion\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "#Read the model, API key and endpoint from the .env file\n",
    "deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env() \n",
    "\n",
    "#We need to add least one model to the kernel\n",
    "#kernel.add_text_completion_service(\"Text Completion\", \n",
    "#                                   AzureTextCompletion(deployment, endpoint, api_key))\n",
    "#Adding a model to the kernel\n",
    "kernel.add_chat_service(\"Chat Completion\",\n",
    "                        AzureChatCompletion(deployment, endpoint, api_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can refer to our Plugin and import it to be able to use its functions.\n",
    "\n",
    "In both **config.json** and **skprompt.txt** files we have defined input parameters that \"**Categorize**\" function requires. In Semantic Kernel we need to use **ContextVariables** to bind values with such parameters. \n",
    "\n",
    "After defining the input variables, we can finally call our semantic function available in our Plugin to perform the expected operation. Please note in the code that we can have multiple functions in a Plugin, so in this case we had to explicitly mention which semantic function we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the callcenter Plugin from the plugins directory, so we can start using its functions \n",
    "callcenter_plugin = kernel.import_semantic_skill_from_directory(\n",
    "    plugins_directory, \"CallCenterPlugin\"\n",
    ")\n",
    "\n",
    "#Defining the input variables for the function\n",
    "var_category = sk.ContextVariables()\n",
    "var_category[\"input\"] = \"My 4G is terrible slow. It's not loading even simple webpages in my mobile.\" #\"It's impossible to work from home as my connection is so unstable. I can't even join a video call!\" \n",
    "var_category[\"categories\"] = \"Landline, Mobile Internet, TV, Fixed Internet/Wifi, Billing\"\n",
    "\n",
    "#Call the plugin with input variables\n",
    "category = await kernel.run_async(\n",
    "    callcenter_plugin[\"categorize\"],\n",
    "    input_vars = var_category\n",
    "    )\n",
    "\n",
    "#Print the output\n",
    "print(f\"Category of the problem: {category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Use Semantic Kernel Tools to add a new Semantic Function\n",
    "\n",
    "Another way to create Semantic Functions is to use [**Sematic Kernel Tools**](https://devblogs.microsoft.com/semantic-kernel/semantic-kernel-tools/), which facilitates the process and simplify testing of semantic functions and other tasks in Semantic Kernel.\n",
    "\n",
    "\n",
    " We'll demonstrate how to use it to create a Semantic Function. Later, you can also refer to this [tutorial](https://learn.microsoft.com/en-us/semantic-kernel/vs-code-tools/).\n",
    "\n",
    " Alternatively, you can run the cells below to create the \"Summarize\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile plugins/CallCenterPlugin/summarize/skprompt.txt\n",
    "Summarize the problem described below. \n",
    "Be brief, yet informative.\n",
    "Try to capture in the summary:\n",
    "- The problem description;\n",
    "- The product customer is complaining (if available);\n",
    "- How agent handled the call;\n",
    "- The outcome of the call. \n",
    "\n",
    "[INPUT]\n",
    "{{$input}}\n",
    "[END INPUT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile plugins/CallCenterPlugin/summarize/config.json\n",
    "{\n",
    "    \"schema\": 1,\n",
    "    \"type\": \"completion\",\n",
    "    \"description\": \"Summarize a problem recorded from a call center of a telco company\",\n",
    "    \"completion\": {\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.6,\n",
    "        \"top_p\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0\n",
    "    },\n",
    "    \"input\": {\n",
    "        \"parameters\": [\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"description\": \"A transcription of a call center conversation. Required parameter.\",\n",
    "                \"defaultValue\": \"\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"default_backends\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, ensure your Plugins folder structure is as follows, as we'll require both Semantic Functions later in this session.\n",
    "\n",
    "```\n",
    "📁 plugins\n",
    "│\n",
    "└─── 📂 CallCenterPlugin\n",
    "     |\n",
    "     └─── 📂 categorize \n",
    "     |      |\n",
    "     |      └───📄 skprompt.txt\n",
    "     |      └───📄 config.json\n",
    "     └─── 📂 summarize \n",
    "     |      |\n",
    "     |      └───📄 skprompt.txt\n",
    "     |      └───📄 config.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - Create and add a Native Function to a Plugin\n",
    "\n",
    "When we think about the concept of AI Apps it's important to remember that an application will certainly require capabilities that will not be provided solely by Large Language Models. For example, performing calculations, retrieving data from a database and even executing API calls are some of the expected capabilities an application generally has. \n",
    "\n",
    "Therefore, we still need to run native code and be able to combine it with AI capabilities to go beyond and create transformative applications powered by modern AI!\n",
    "\n",
    "In semantic Kernel we can add native code in different languages, like C# and Python, to be part of our Plugins. We should use the same folder structure from before, however, instead of prompts and configurations, we will have native code, like .py (Python) or .cs (C#) files.\n",
    "\n",
    "For example, let's assume that we want to add a new function to \"CallCenter\" Plugin to transcribe audio files using. Let's see how our folder structure would look like:\n",
    "\n",
    "```\n",
    "📁 plugins\n",
    "│\n",
    "└─── 📂 CallCenterPlugin\n",
    "     |\n",
    "     └─── 📂 categorize \n",
    "     |      |\n",
    "     |      └───📄 skprompt.txt\n",
    "     |      └───📄 config.json\n",
    "     |\n",
    "     |\n",
    "     └───📄 Transcribe.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1) Transform an existing code into a Native Function for Semantic Kernel\n",
    "Let's assume we already have a base code in Python that is capable of transcribing an audio file to text, as shown below:\n",
    "\n",
    "```python\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# Define the transcribe_audio function\n",
    "def transcribe_audio(audio_file, language, subscription_key, region):\n",
    "    # Set up the speech configuration\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)\n",
    "    # Define the language of the audio file\n",
    "    speech_config.speech_recognition_language = language\n",
    "\n",
    "    # Open the audio file\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=audio_file)\n",
    "    \n",
    "    #Code commited for simplicity\n",
    "    \"...\"\n",
    "    \n",
    "    # Convert to string and return the transcription\n",
    "    return recognized_text_list\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " We need to do some small changes in the code to ensure it can become a native function and can be addedd to our Plugin in Semantic Kernel. In summary:\n",
    "- **Transform it in a class:** all native functions must be defined as public methods that belong to a class. This class will represent our Plugin.\n",
    "- **Import the required libraries:** you need to import the _skill_definition_ module to be able to use the decorators and _SKContext_ module to parse multiple input variables.\n",
    "```python\n",
    "#Importing Azure Cognitive Services Speech SDK package\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "#Importing Semantic Kernel packages to define the function and its parameters\n",
    "from semantic_kernel.skill_definition import (\n",
    "    sk_function,\n",
    "    sk_function_context_parameter,\n",
    ")\n",
    "#Importing Semantic Kernel package to parse input variables\n",
    "from semantic_kernel.orchestration.sk_context import SKContext\n",
    "#Defining the Transcribe class to be used as a plugin to transcribe audio files\n",
    "class Transcribe:\n",
    "...\n",
    "```\n",
    "- **Add the decorator @sk_function:** the kernel will use this decorator to be able to register this function as the plugin is loaded. The decorator will also describe the function and its input parameter (if only one), as described in the [documentation](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/plugins/native-functions/using-the-skfunction-decorator?tabs=python#use-the-skfunction-decorator-to-define-a-native-function). Such information will be later used by Planners to orchestrate Plugins.\n",
    "- **Add the decorator sk_function_context_parameter:** if your function has multiple input parameters you need to use this decorator to describe the input parameters with their names and description, so the kernel understand how to call the function and orchestrate them in Planners.\n",
    "```python\n",
    "@sk_function(\n",
    "    description=\"Transcribe an audio file. Suitable for long audio files\",\n",
    "    name=\"transcribe_audio\",\n",
    ")\n",
    "@sk_function_context_parameter(\n",
    "    name=\"audio_path\",\n",
    "    description=\"The path to the audio file to transcribe\",\n",
    ")\n",
    "@sk_function_context_parameter(\n",
    "    name=\"language\",\n",
    "    description=\"The language of the audio file in the format of Locale (BCP-47) (e.g. en-US)\",\n",
    ")\n",
    "@sk_function_context_parameter(\n",
    "    name=\"subscription_key\",\n",
    "    description=\"The subscription key for the Azure AI Speech resource\",\n",
    ")\n",
    "@sk_function_context_parameter(\n",
    "    name=\"region\",\n",
    "    description=\"The region of the Azure AI Speech resource\",\n",
    ")         \n",
    "def transcribe_audio(self, context: SKContext) -> str:\n",
    "```\n",
    "- **Use SKContext to handle input parameters:** if your function requires multiple input parameters, you need to add _SKContext_ as the input of your function and map the individual parameters inside the function. See more details [here](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/plugins/native-functions/multiple-parameters?tabs=python#using-context-parameters-to-pass-multiple-inputs).\n",
    "```python\n",
    "    #Obtaining and parsing input parameters from SKContext\n",
    "    audio_path = context[\"audio_path\"]\n",
    "    language = context[\"language\"]\n",
    "    subscription_key = context[\"subscription_key\"]\n",
    "    region = context[\"region\"]\n",
    "```\n",
    "\n",
    "Let's review our modified code directly in the **[\"transcribe.py\"](./plugins/CallCenterPlugin/Transcribe.py)** file in the plugins directory. If the file is not available, you can run the file below to create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile plugins/CallCenterPlugin/Transcribe.py\n",
    "import time\n",
    "\n",
    "#Importing Azure Cognitive Services Speech SDK package\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "#Importing Semantic Kernel packages to define the function and its parameters\n",
    "from semantic_kernel.skill_definition import (\n",
    "    sk_function,\n",
    "    sk_function_context_parameter,\n",
    ")\n",
    "#Importing Semantic Kernel package to parse input variables\n",
    "from semantic_kernel.orchestration.sk_context import SKContext\n",
    "\n",
    "#Defining the Transcribe class to be used as a plugin to transcribe audio files\n",
    "class Transcribe:\n",
    "    @sk_function(\n",
    "        description=\"Transcribe an audio file and output its text transcription.\",\n",
    "        name=\"transcribe_audio\",\n",
    "    )\n",
    "    @sk_function_context_parameter(\n",
    "        name=\"input\",\n",
    "        description=\"The path in disk to the audio file to transcribe. Required parameter\",\n",
    "    )\n",
    "    @sk_function_context_parameter(\n",
    "        name=\"language\",\n",
    "        description=\"The language of the audio file in the format of Locale (BCP-47) (e.g. en-US). Required parameter\",\n",
    "    )\n",
    "    @sk_function_context_parameter(\n",
    "        name=\"subscription_key\",\n",
    "        description=\"The subscription key for the Azure AI Speech resource. Required parameter.\",\n",
    "    )\n",
    "    @sk_function_context_parameter(\n",
    "        name=\"region\",\n",
    "        description=\"The region of the Azure AI Speech resource. Required parameter.\",\n",
    "    )         \n",
    "    def transcribe_audio(self, context: SKContext) -> str:\n",
    "        #Obtaining and parsing input parameters from SKContext\n",
    "        audio_path = context[\"input\"]\n",
    "        language = context[\"language\"]\n",
    "        subscription_key = context[\"subscription_key\"]\n",
    "        region = context[\"region\"]\n",
    "\n",
    "        #Set up the speech configuration\n",
    "        speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)\n",
    "        # Define the language of the audio file\n",
    "        speech_config.speech_recognition_language = language\n",
    "\n",
    "        # Open the audio file\n",
    "        audio_config = speechsdk.audio.AudioConfig(filename=audio_path)\n",
    "\n",
    "        # Create a speech recognizer\n",
    "        speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "        # Define global variables to control the continuous recognition loop and accumulate text\n",
    "        global done \n",
    "        done = False\n",
    "        global recognized_text_list \n",
    "        recognized_text_list=[]\n",
    "\n",
    "        # Define the stop callback function\n",
    "        def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "            \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "            print('CLOSING on {}'.format(evt))\n",
    "            global done\n",
    "            done = True\n",
    "\n",
    "        # Define the recognize callback function\n",
    "        def recognize_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "            \"\"\"callback for recognizing the recognized text\"\"\"\n",
    "            global recognized_text_list\n",
    "            recognized_text_list.append(evt.result.text)\n",
    "\n",
    "        # Connect callbacks to the events fired by the speech recognizer\n",
    "        speech_recognizer.recognized.connect(recognize_cb)\n",
    "        speech_recognizer.session_started.connect(lambda evt: print('STT SESSION STARTED: {}'.format(evt)))\n",
    "        speech_recognizer.session_stopped.connect(lambda evt: print('STT SESSION STOPPED {}'.format(evt)))\n",
    "        speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    \n",
    "        # Start continuous speech recognition\n",
    "        speech_recognizer.start_continuous_recognition()\n",
    "        print(\"Continuous speech recognition started. Waiting to complete transcription...\")\n",
    "        while not done:\n",
    "            time.sleep(.1)\n",
    "\n",
    "        #Stop continuous speech recognition\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "        \n",
    "        print(\"Transcription complete.\")\n",
    "                \n",
    "        return str(recognized_text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2) Calling a Native Function with Semantic Kernel\n",
    "Now that we already have created our native function that's capable of Transcribing an audio file, let's see how can we import and use it.\n",
    "\n",
    "The process is similar to Semantic Functions, but there's a change on how we import each of them. The native functions are imported as \"Plugins\" following the hierarchy and folder structure we already explored. Once we have the plugin ready as part of ou Import statement, we can use the kernel to load it using the name of the Class.\n",
    "\n",
    "Finally, we'll define the input parameters our function requires as our Context and call the function using the kernel to run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the native function within the Plugin\n",
    "from plugins.CallCenterPlugin.Transcribe import Transcribe\n",
    "\n",
    "#Loading the .env file to use Azure AI Speech\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#Load sensitive data from .env file to use Azure AI Speech\n",
    "load_dotenv()\n",
    "\n",
    "#Import the call center plugin to use the transcription\n",
    "transcribe_fn = kernel.import_skill(Transcribe(), skill_name=\"CallCenterPlugin\")\n",
    "\n",
    "#Defining the input variables for the transcription funcion\n",
    "var_transcribe = sk.ContextVariables()\n",
    "var_transcribe[\"input\"] = \"./audio/enUS_long_network_interference.wav\"#./audio/english_billing_process_sample.wav\" #\"./audio/enUS_short_wifiproblem.wav\"\n",
    "var_transcribe[\"language\"] = \"en-US\"\n",
    "var_transcribe[\"subscription_key\"] = os.getenv(\"AZURE_AI_SPEECH_KEY\")\n",
    "var_transcribe[\"region\"] = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "\n",
    "#Call the plugin with input variables\n",
    "transcription = await kernel.run_async(\n",
    "    transcribe_fn[\"transcribe_audio\"],\n",
    "    input_vars = var_transcribe\n",
    "    )\n",
    "\n",
    "print(f\"Transcription: {transcription.result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 - Puting it all together for a Call Center Analytics solution\n",
    "Now, let's see a simple example for a Call Center Analytics solution where we:\n",
    "- Use an audio as input (previous step);\n",
    "- Use a Native Function to obtain the transcription from the audio (previous step);\n",
    "- Use a Semantic Function to summarize the problem;\n",
    "- Use a Semantic Function to category the problem;\n",
    "\n",
    " This is one way to chain functions together and manually orchestrate them. In another Lesson, we'll explore how to automate plugins orchestration with Planners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the native functions from the Plugin\n",
    "callcenter_plugin = kernel.import_semantic_skill_from_directory(plugins_directory, \"CallCenterPlugin\")\n",
    "\n",
    "#Define the functions that will be used from the plugin\n",
    "summarize_fn = callcenter_plugin[\"summarize\"]\n",
    "categorize_fn = callcenter_plugin[\"categorize\"]\n",
    "\n",
    "#Create the summary from the Transcription, running the Semantic Function\n",
    "summary = summarize_fn.invoke(transcription.result)\n",
    "\n",
    "#Define the Summary as the input for the problem categorization and run the Semantic Function\n",
    "var_category[\"input\"] = summary.result\n",
    "category = categorize_fn.invoke(variables = var_category)\n",
    "\n",
    "#Print the results\n",
    "print(f\"1) Transcription: {transcription.result} \\n2) Summary: {summary.result} \\n3)Problem Category: {category.result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also chain functions together in a sequential pipeline. In this scenario, the output of one functions acts as the input for the next one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential pipeline to summarize and then extract the category of a problem reported in a call center conversation\n",
    "result = await kernel.run_async(summarize_fn, categorize_fn, input_str=transcription.result)\n",
    "\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Orchestrate AI Plugins with Planners\n",
    "#### Step 1 - Background\n",
    "\n",
    "Foundation Models are revolutionizing how we as humans interact with machines, as they exceed in two important capabilities: \n",
    "- **Natural Language:** the models are capable of \"understanding\" how humans communicate instead of humans making adaptions to interact with machines using traditional hardware (mouse/keyboard) and UI/UX. \n",
    "- **Reasoning Engine:** the models can reason over prompts (and even videos, audio and images with multimodal) and provide outcomes from that. Traditionally, we would need to deterministically program all the application.\n",
    "\n",
    "The planners are a great example on how we can combine both capabilities to create even richer experiences that are powered by AI. Planners are capable of transforming a high-level natural language **\"ASK\"** into a step-by-step **\"PLAN\"** (reasoning) on how to achieve that **\"GOAL\"**.\n",
    "\n",
    "To do so, the Planner will try to use tools (i.e., Plugins) already loaded into the Kernel and both their native and semantic functions. Here's a high-level view on how the Planner select from available plugins to create a logical plan with the order that each step will be called.  \n",
    "![Planners](https://learn.microsoft.com/en-us/semantic-kernel/media/the-planner.png)\n",
    "\n",
    "To determine which Functions should be used and how to use it, the Planner relies on the **Description** of the functions and its parameters. Theferore, always try to describe your functions and parameters the best and clear as way as possible. Giving hints about the expected output and informing which parameters are mandatory can also improve the results when working with Planners.\n",
    "\n",
    "Planners works as any other Semantic Function. It means that you can define your own planners writing a Prompt in a **skprompt.txt** file. We'll not explore how to create your own planner is this lab, but you can review the prompts for other planners. \n",
    "\n",
    "Currently, there're 4 types of out-of-the-box Planners available in Semantic Kernel for Python as described below:\n",
    "| Planner | Description | Prompts |\n",
    "| -------- | -------- | -------- |\n",
    "|**ActionPlanner**| Creates a plan with a single step determining a single function to be called| [Link](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/action_planner/skprompt.txt) |\n",
    "|**BasicPlanner** | A simplified version of SequentialPlanner that strings together a set of functions|[Link](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/basic_planner.py) |\n",
    "|**SequentialPlanner**| Creates a plan with a series of steps that are interconnected with custom generated input and output variables| [Link](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/sequential_planner/Skills/SequentialPlanning/skprompt.txt)|\n",
    "|**StepwisePlanner**|Incrementally performs steps and observes any results before performing the next step.|[Link](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/stepwise_planner/Skills/StepwiseStep/skprompt.txt) |\n",
    "\n",
    "Planners are evolving fast, so let's explore some of them and demonstrate how they work with some examples.\n",
    "\n",
    "**Important:** As planners rely on their \"reasoning\" capability, generally we can obtain better results with more powerful models, like GPT-4. Please review your `.env` file below to ensure we're using this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .env\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"\" #Model Deployment name, like gpt-4\n",
    "AZURE_OPENAI_ENDPOINT=\"\" #Azure OpenAI Service endpoint, like https://cog-azopenai-demos.openai.azure.com/\n",
    "AZURE_OPENAI_API_KEY=\"\" #Azure OpenAI Service API Key\n",
    "AZURE_AI_SPEECH_KEY=\"\" #Azure Speech Service API Key\n",
    "AZURE_AI_SPEECH_REGION=\"\" #Azure Speech Service Region, like brazilsouth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Action Planner\n",
    "As the solutions grow in complexity and more Plugins are developed, we may need to choose a **single** best Plugin to achieve our goal, or **ASK**. The Action Planner picks the best plugin to do what the user wants. It is different from other planners because it only runs one plugin at a time.\n",
    "\n",
    "Let's run a example for the Action Planner. \n",
    "\n",
    "**Notice:** In this example, we'll import several [Core Plugins](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/plugins/out-of-the-box-plugins?tabs=python#core-plugins) (shipped with Semantic Kernel) and other plugins available as samples from [Semantic Kernel GitHub repo](https://github.com/microsoft/semantic-kernel/). You can browse an explore then later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "#Import the Planner from its module. Planners are part of \"planning\" module\n",
    "from semantic_kernel.planning import ActionPlanner\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "#Read the model, API key and endpoint from the .env file\n",
    "deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env() \n",
    "\n",
    "#Adding a model to the kernel\n",
    "kernel.add_chat_service(\"Chat Completion\",\n",
    "                        AzureChatCompletion(deployment, endpoint, api_key))\n",
    "\n",
    "#Create the Planner\n",
    "planner = ActionPlanner(kernel)\n",
    "\n",
    "#Now, we'll add the Plugins that the kernel will be allowed to use. In this case, we're importing only core Plugins \n",
    "from semantic_kernel.core_skills import MathSkill, TimeSkill\n",
    "kernel.import_skill(MathSkill(), \"math\")\n",
    "kernel.import_skill(TimeSkill(), \"time\")\n",
    "\n",
    "#Let's see which Plugins are available for the Planner\n",
    "print(f\"List of available Plugins for the Planner: {list(kernel.skills.data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the list of Plugins available, let's create our plan for a ASK that can be solved with one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to inform what we need to achieve to the planner define which Plugins (and Functions it'll pick)\n",
    "ask = \"What is the time right now?\"\n",
    "\n",
    "try:\n",
    "    #Now we'll ask our planner to create a plan to achieve the goal we defined\n",
    "    plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "    #And execute the plan\n",
    "    result = await plan.invoke_async()\n",
    "    print(f\"Result: {result}\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ActionPlanner picked a single Plugin (and function) to get back to us with a Response based on our ask. Eventually, our ask may require Plugins that are not available (or were not loaded) in the kernel. Let's see an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see which Plugins are available for the Planner\n",
    "print(f\"List of available Plugins for the Planner: {list(kernel.skills.data.keys())}\")\n",
    "\n",
    "#Defining a different ask for a Plugin that is not available\n",
    "ask = \"Translate the following text to Spanish: I love Semantic Kernel\"\n",
    "\n",
    "try:\n",
    "    #Creating and executing the Plan\n",
    "    plan = await planner.create_plan_async(goal=ask)\n",
    "    result = await plan.invoke_async()\n",
    "    print(f\"Result: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we got an error / no result as we haven't loaded any Plugins that are capable of translations. Let's import a new Plugin into the Kernel and see how we can list the functoins available for the Planner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define where the plugins are stored. If your plugins are in a different directory, change this parameter.\n",
    "sample_plugins_directory = \"./sksampleplugins\"\n",
    "\n",
    "#Adding the WriterPlugin to the kernel, which has a function to translate text\n",
    "writer_plugin = kernel.import_semantic_skill_from_directory(sample_plugins_directory, \"WriterPlugin\")\n",
    "\n",
    "#Let's see which Plugins and  available now and their fuctions\n",
    "for plugin_name, functions in kernel.skills.data.items():  \n",
    "    print(f\"Plugin: {plugin_name}\")  \n",
    "    for function_name in functions.keys():  \n",
    "        print(f\"  Function: {function_name}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as we now have the proper Plugin, let's see how the same \"ASK\" is handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have the WriterPlugin imported, we can use its functions\n",
    "ask = \"Translate the following text to Spanish: I love Semantic Kernel\"\n",
    "\n",
    "try:\n",
    "    #Creating and executing the Plan\n",
    "    plan = await planner.create_plan_async(goal=ask)\n",
    "    result = await plan.invoke_async()\n",
    "    print(f\"Result: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Basic Planner\n",
    "We saw how the Action Planner can help to find a single Plugin to achieve a goal, however, most of the times, the real power is to combine several Plugins in a given order to achieve a goal, which is the role of **Sequential Planner** and **Basic Planner**. Since they're similar, we'll explore only Basic Planner (later we'll see Sequential Planner in another lab).\n",
    "\n",
    "The Basic Planner will produce a plan (in JSON format) stating the steps (i.e, functions inside Plugins) it'll use to achieve the goal. Each step is run and evaluated sequentially.\n",
    "\n",
    "Let's how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import BasicPlanner\n",
    "\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "#Import the Planner from its module. Planners are part of \"planning\" module\n",
    "from semantic_kernel.planning import ActionPlanner\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "#Read the model, API key and endpoint from the .env file\n",
    "deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env() \n",
    "\n",
    "#Adding a model to the kernel\n",
    "kernel.add_chat_service(\"Chat Completion\",\n",
    "                        AzureChatCompletion(deployment, endpoint, api_key))\n",
    "\n",
    "#Define where the plugins are stored. If your plugins are in a different directory, change this parameter.\n",
    "sample_plugins_directory = \"./sksampleplugins\"\n",
    "\n",
    "#Defining a single Plugin with several functions to be used by the Planner\n",
    "writer_plugin = kernel.import_semantic_skill_from_directory(sample_plugins_directory, \"WriterPlugin\")\n",
    "\n",
    "#Define the Planner\n",
    "planner = BasicPlanner()\n",
    "\n",
    "#Define the goal for the planner\n",
    "ask = \"\"\"Generate taglines for a telco company for a marketing campaign. \n",
    "Translate each of the ideias to Spanish as bullet points and send as an email to Marketing. \n",
    "\"\"\"\n",
    "#Let's see which Plugins are available now\n",
    "print(f\"List of available Plugins for the Planner: {list(kernel.skills.data.keys())}\")\n",
    "\n",
    "#Print the steps of the plan\n",
    "try:\n",
    "    plan = await planner.create_plan_async(goal=ask, kernel=kernel)\n",
    "    print(f\"Plan: {plan.generated_plan}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Basic Planner used the LLM to produce a plan on how to achieve the goal given user's ask. The plan is a sequence of subtasks each represented by a function among loaded Plugins. The input is extracted from user's ask and the otuput of each step is the input for the next one.\n",
    "\n",
    "Also notice that the plan has also determined additional parameters for the functions when required.\n",
    "\n",
    "Eventually, the plan may not look like as expected, so run previous cell to ensure the plan looks accurate for the given ask.\n",
    "\n",
    " If the plan is correct, let's execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to execute the plan\n",
    "try:\n",
    "    result = await planner.execute_plan_async(plan, kernel)\n",
    "    print(f\"Result: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - Stepwise Planner to orchestrate a Call Center Analytics solution\n",
    "\n",
    "In challenging scenarios, the previous planners may not be able to achieve user's goal in a sequential way. One alternative for planning is to ask the LLM to propose a high-level plan, execute each step and **reason** if the output helps or not to achieve user's goal, adjusting the plan accordingly until the goal is met or the maximum if iterations is reached. \n",
    "\n",
    "StepWise Planner does exactly that, inspired on advanced techniques, like [**Modular Reasoning, Knowledge and Language - MRKL**](https://arxiv.org/abs/2210.03629) and [**ReACT pattern**](https://arxiv.org/abs/2210.03629). For each step, this planner will produce:\n",
    "- **Thoughts:** what the LLM believe, in natural language, it's required to do Next to be closer to achieve user's goal;\n",
    "- **Actions:** what kind of action (i.e, Functions from a Plugin with its parameters) they will do next to achieve the THOUGHT.\n",
    "- **Observations:** outputs produced from the ACTION that can be a final answer or the input for the next THOUGHT.\n",
    "\n",
    "Each step should help the plan to com closer to user's goal. However, sometimes the planner may fail to converge to a solution. Therefore, it's possible to control the maximum number of interactions the plan it'll take. Also note that each step is a request to the LLM. Therefore, it's important to think on costs when using this type of planner. Moreover, planners in general can be unpredictable sometimes, so always evaluate well before using them for critical scenarios in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how we can use this Planner to run our **Call Center Analytics Scenario** in a more autonomous way. Our goal is to run all the steps below from a single \"ask\" in natural language using StepWise Planner."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    +---------------------+            +------------------------+            +----------------------+            +-------------------+\n",
    "    | Transcribe          |            | Summarize              |            | Categorize           |            | WriteEmail        |\n",
    "    | (CallCenter Plugin) |            | (CallCenter Plugin)    |            | (CallCenter Plugin)  |            | (Writer Plugin)   |\n",
    "    +---------------------+            +------------------------+            +----------------------+            +-------------------+\n",
    "Audio-> |                                             |                           |                               |\n",
    "        | Transcription                               |                           |                               |\n",
    "        |-------------------------------------------->|                           |                               |\n",
    "        |                                             |                           |                               |\n",
    "        |                                             |                           |                               |\n",
    "        |                                             | Summary                   |                               |                \n",
    "        |                                             |-------------------------> |                               |\n",
    "        |                                             |                           | Category                      |\n",
    "        |                                             | Summary                   | ----------------------------->|\n",
    "        |                                             |---------------------------------------------------------->| -> Email to customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "#Importing modules required for this Planner\n",
    "from semantic_kernel.planning import StepwisePlanner\n",
    "from semantic_kernel.planning.stepwise_planner.stepwise_planner_config import (\n",
    "    StepwisePlannerConfig,\n",
    ")\n",
    "\n",
    "#Importing the native function within the Plugin\n",
    "from plugins.CallCenterPlugin.Transcribe import Transcribe\n",
    "\n",
    "#Importing required modules to load sensitive data from .env file\n",
    "from dotenv import load_dotenv \n",
    "import os\n",
    "\n",
    "#Load sensitive data from .env file to use Azure AI Speech\n",
    "load_dotenv()\n",
    "\n",
    "#Read the model, API key and endpoint from the .env file\n",
    "deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "\n",
    "#Reloading kernel and chat servince to ensure it's accurate\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "#Adding a LLM to be used by the kernel\n",
    "kernel.add_chat_service(\"Chat Completion\",\n",
    "                        AzureChatCompletion(deployment, endpoint, api_key))\n",
    "\n",
    "#Define where the plugins are stored. If your plugins are in a different directory, change this parameter.\n",
    "plugins_directory = \"./plugins\"\n",
    "sample_plugins_directory = \"./sksampleplugins\"\n",
    "\n",
    "#Now, we'll add the Plugins that the kernel will be allowed to use. \n",
    "# In this case, we're importing core native functions from Call Center Plugin and semantic functions from Writer Plugin and Call Center Plugin \n",
    "kernel.import_skill(Transcribe(), \"CallCenterPlugin\")\n",
    "callcenter_plugin = kernel.import_semantic_skill_from_directory(plugins_directory, \"CallCenterPlugin\")\n",
    "writer_plugin = kernel.import_semantic_skill_from_directory(sample_plugins_directory, \"WriterPlugin\")\n",
    "\n",
    "#Let's confirm which Plugins are available for the Planner use\n",
    "print(f\"List of available Plugins for the Planner: {list(kernel.skills.data.keys())}\")\n",
    "\n",
    "#Defining the input variables for the transcription funcion\n",
    "transcription_param = {}\n",
    "transcription_param[\"input\"] = \"./audio/english_billing_process_sample.wav\" #\"./audio/enUS_short_wifiproblem.wav\"\n",
    "transcription_param[\"language\"] = \"en-US\"\n",
    "transcription_param[\"subscription_key\"] = os.getenv(\"AZURE_AI_SPEECH_KEY\")\n",
    "transcription_param[\"region\"] = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "\n",
    "#Defining the ask in a single statement \n",
    "ask = f\"\"\"\n",
    "Transcribe the audio file, summarize the incident and extract the category of the problem as Mobile Internet, Fixed Internet, Wifi/Router or Billing.\n",
    "Write an apology email to Customer demonstrating that you understood their problem. Be brief in the email. \n",
    "Audio transcription details: \"{transcription_param}\"\n",
    "\"\"\"\n",
    "\n",
    "#Create the plan already defining the max number of iterations and how fast each interaction should be  \n",
    "planner = StepwisePlanner(\n",
    "    kernel, StepwisePlannerConfig(max_iterations=10, min_iteration_time_ms=1000)\n",
    ")\n",
    "\n",
    "#Try to create the plan\n",
    "try:\n",
    "    plan = planner.create_plan(goal=ask)  \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leet's execute the plan and see it's response. It can take sometime depending on the type of functions used and the number of interactions that the plan take to converge to a solution. Remember that each step is a call to the LLM, so Costs are also an important consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to execute the plan. It can take sometime due to the transcription duration and the number of steps expected in the plan\n",
    "try:\n",
    "    result = await plan.invoke_async()\n",
    "    print(f\"Result: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can review what were the steps that the plan took to seek user's goal. Please note Thoughts, Actions and Observations as intermediary steps towards a solution. Since Stepwise Planner builds the plan in runtime, as it executes actions and reason over each observation, we can see the full plan after the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing steps taken by the plan\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(\"Step:\", index)\n",
    "    print(\"Description:\",step.description)\n",
    "    print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
    "    if len(step._outputs) > 0:\n",
    "        print( \"  Output:\\n\", str.replace(result[step._outputs[0]],\"\\n\", \"\\n  \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
