# Sematic Kernel Workshop

Learn how to build LLM Apps with Semantic Kernel through self-contained and independent lessons, in a flexible way so that you can choose the sequence that is most convenient for you. 

Typically, each lesson is structured to last an hour, and it is assumed that students already have some Python or coding skills for the hands-on labs.

## Objectives

After completing this workshop, students will be able to:

* Author their own copilots using Semantic Kernel.

* Create AI plugins using semantic and native functions.

* Automate complex tasks execution with planners.

* Create prompt templates to define AI functions.

* Embed Generative AI in their applications.


## Contents

##### 1 Background - Introduction to LLMs  
 - Introduction to LLMs GPTs and other models.
 - Azure AI Services Overview.
 - Azure OpenAI Service Overview.

##### 2 CoPilot Stack and Semantic Kernel
 - Introduction to Copilots.
 - Microsoft Copilots.
 - Build your own Copilots.  
 - Copilot ecosystem (Copilots + Plugins).
 - What is Semantic Kernel?
 - Why Semantic Kernel?
 - The role of the kernel.

##### 3 Semantic Kernel Basic Concepts  
 - Native and Semantic Functions.
 - Create AI Plugins from functions.
 - Chain plugins together.

##### 4 Semantic Kernel Advanced Topics
 - Add Memory to your AI Apps.
 - Use Planners to automate Plugins orchestration.
 - Calling external connectors.

##### 5 Best Practices and Lessons Learned
 - Learn some best practices on service limits.
 - Final discussions and wrap-up.

## Requirements

- Workstation

    - [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli)
    - [Anaconda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html)
    - [VS Code](https://code.visualstudio.com/)

- Cloud

    - [Azure Subscription](https://azure.com)
    <!-- - [Github.com Account](https://github.com) -->